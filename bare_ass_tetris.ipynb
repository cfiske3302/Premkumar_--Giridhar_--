{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "pygame 2.5.2 (SDL 2.28.3, Python 3.10.13)\n",
                        "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import sys\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "sys.path.insert(0, './TetrisEnv')\n",
                "from TetrisBattle.envs.tetris_env import TetrisSingleEnv, TetrisEnv\n",
                "from TetrisBattle import *\n",
                "# %pip install -e ./TetrisEnv\n",
                "# import TetrisBattle"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from gym.wrappers import GrayScaleObservation\n",
                "from preprocessing.EensyWeensy import MakeEensyWeensy\n",
                "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
                "# from gym import make\n",
                "# env = make('SinglePTetris-v0')\n",
                "env = TetrisSingleEnv()\n",
                "ob = env.reset()\n",
                "dots = np.ones((20, 10))\n",
                "x = 100\n",
                "y = 130\n",
                "ob[x:x+10,y:y+10] = [255,255,255]\n",
                "plt.imshow(ob, cmap=\"plasma\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Box(0, 255, (150, 100, 4), uint8)\n"
                    ]
                }
            ],
            "source": [
                "print(env.observation_space)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/miniconda3/envs/ECE_113_Capstone_1/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
                        "  warnings.warn(\n"
                    ]
                }
            ],
            "source": [
                "env = GrayScaleObservation(env, keep_dim=True)\n",
                "env = MakeEensyWeensy(env, cut_in_half=True, scale=.25)\n",
                "env = DummyVecEnv([lambda: env])\n",
                "env = VecFrameStack(env, 4, channels_order=\"last\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(1, 150, 100, 4)"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ob,_,_,_ = env.step([0])\n",
                "ob.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# for i in range(0, 1000):\n",
                "#     action = env.random_action()\n",
                "#     state, reward, done, info = env.step(action)\n",
                "#     env.render()\n",
                "#     i += 1\n",
                "# env.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "True\n"
                    ]
                }
            ],
            "source": [
                "import os \n",
                "from stable_baselines3 import PPO\n",
                "from stable_baselines3.common.callbacks import BaseCallback\n",
                "from stable_baselines3.common.env_checker import check_env\n",
                "import torch\n",
                "print(torch.cuda.is_available())\n",
                "check_env(TetrisSingleEnv())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "class TrainAndLoggingCallback(BaseCallback):\n",
                "\n",
                "    def __init__(self, check_freq, save_path, verbose=1):\n",
                "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
                "        self.check_freq = check_freq\n",
                "        self.save_path = save_path\n",
                "\n",
                "    def _init_callback(self):\n",
                "        if self.save_path is not None:\n",
                "            os.makedirs(self.save_path, exist_ok=True)\n",
                "\n",
                "    def _on_step(self):\n",
                "        if self.n_calls % self.check_freq == 0:\n",
                "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
                "            self.model.save(model_path)\n",
                "\n",
                "        return True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "CHECKPOINT_DIR = './train/'\n",
                "LOG_DIR = './logs/'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using cuda device\n",
                        "Wrapping the env in a VecTransposeImage.\n"
                    ]
                }
            ],
            "source": [
                "try:\n",
                "    del model\n",
                "except NameError:\n",
                "    pass\n",
                "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=1e-2, n_steps=512, device=\"cuda\") "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Logging to ./logs/PPO_27\n",
                        "---------------------------------\n",
                        "| rollout/           |          |\n",
                        "|    ep_len_mean     | 79.7     |\n",
                        "|    ep_rew_mean     | -37.8    |\n",
                        "| time/              |          |\n",
                        "|    fps             | 74       |\n",
                        "|    iterations      | 1        |\n",
                        "|    time_elapsed    | 6        |\n",
                        "|    total_timesteps | 512      |\n",
                        "---------------------------------\n",
                        "---------------------------------------\n",
                        "| rollout/                |           |\n",
                        "|    ep_len_mean          | 143       |\n",
                        "|    ep_rew_mean          | -36.2     |\n",
                        "| time/                   |           |\n",
                        "|    fps                  | 70        |\n",
                        "|    iterations           | 2         |\n",
                        "|    time_elapsed         | 14        |\n",
                        "|    total_timesteps      | 1024      |\n",
                        "| train/                  |           |\n",
                        "|    approx_kl            | 9.327778  |\n",
                        "|    clip_fraction        | 0.951     |\n",
                        "|    clip_range           | 0.2       |\n",
                        "|    entropy_loss         | -0.182    |\n",
                        "|    explained_variance   | -0.000216 |\n",
                        "|    learning_rate        | 0.01      |\n",
                        "|    loss                 | 12.2      |\n",
                        "|    n_updates            | 10        |\n",
                        "|    policy_gradient_loss | 0.49      |\n",
                        "|    value_loss           | 1.12e+03  |\n",
                        "---------------------------------------\n",
                        "------------------------------------------\n",
                        "| rollout/                |              |\n",
                        "|    ep_len_mean          | 143          |\n",
                        "|    ep_rew_mean          | -36.2        |\n",
                        "| time/                   |              |\n",
                        "|    fps                  | 69           |\n",
                        "|    iterations           | 3            |\n",
                        "|    time_elapsed         | 22           |\n",
                        "|    total_timesteps      | 1536         |\n",
                        "| train/                  |              |\n",
                        "|    approx_kl            | 0.0016784453 |\n",
                        "|    clip_fraction        | 0.0252       |\n",
                        "|    clip_range           | 0.2          |\n",
                        "|    entropy_loss         | -0.105       |\n",
                        "|    explained_variance   | 0.133        |\n",
                        "|    learning_rate        | 0.01         |\n",
                        "|    loss                 | 1.3          |\n",
                        "|    n_updates            | 20           |\n",
                        "|    policy_gradient_loss | -0.00107     |\n",
                        "|    value_loss           | 2.29         |\n",
                        "------------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 143        |\n",
                        "|    ep_rew_mean          | -36.2      |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 70         |\n",
                        "|    iterations           | 4          |\n",
                        "|    time_elapsed         | 29         |\n",
                        "|    total_timesteps      | 2048       |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.25272918 |\n",
                        "|    clip_fraction        | 0.0312     |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -0.0669    |\n",
                        "|    explained_variance   | -0.106     |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 0.345      |\n",
                        "|    n_updates            | 30         |\n",
                        "|    policy_gradient_loss | 0.00795    |\n",
                        "|    value_loss           | 0.562      |\n",
                        "----------------------------------------\n",
                        "-------------------------------------------\n",
                        "| rollout/                |               |\n",
                        "|    ep_len_mean          | 257           |\n",
                        "|    ep_rew_mean          | -35.5         |\n",
                        "| time/                   |               |\n",
                        "|    fps                  | 70            |\n",
                        "|    iterations           | 5             |\n",
                        "|    time_elapsed         | 36            |\n",
                        "|    total_timesteps      | 2560          |\n",
                        "| train/                  |               |\n",
                        "|    approx_kl            | 3.2782555e-07 |\n",
                        "|    clip_fraction        | 0             |\n",
                        "|    clip_range           | 0.2           |\n",
                        "|    entropy_loss         | -0.00303      |\n",
                        "|    explained_variance   | 0             |\n",
                        "|    learning_rate        | 0.01          |\n",
                        "|    loss                 | 0.28          |\n",
                        "|    n_updates            | 40            |\n",
                        "|    policy_gradient_loss | -1.11e-09     |\n",
                        "|    value_loss           | 2.73          |\n",
                        "-------------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 257         |\n",
                        "|    ep_rew_mean          | -35.5       |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 70          |\n",
                        "|    iterations           | 6           |\n",
                        "|    time_elapsed         | 43          |\n",
                        "|    total_timesteps      | 3072        |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.000960674 |\n",
                        "|    clip_fraction        | 0.00195     |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.0253     |\n",
                        "|    explained_variance   | 0.0154      |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 0.0505      |\n",
                        "|    n_updates            | 50          |\n",
                        "|    policy_gradient_loss | -0.000156   |\n",
                        "|    value_loss           | 0.188       |\n",
                        "-----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 375         |\n",
                        "|    ep_rew_mean          | -35.1       |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 70          |\n",
                        "|    iterations           | 7           |\n",
                        "|    time_elapsed         | 51          |\n",
                        "|    total_timesteps      | 3584        |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.003405289 |\n",
                        "|    clip_fraction        | 0.00195     |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.0113     |\n",
                        "|    explained_variance   | 0           |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 0.252       |\n",
                        "|    n_updates            | 60          |\n",
                        "|    policy_gradient_loss | -8.89e-05   |\n",
                        "|    value_loss           | 0.403       |\n",
                        "-----------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 375        |\n",
                        "|    ep_rew_mean          | -35.1      |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 69         |\n",
                        "|    iterations           | 8          |\n",
                        "|    time_elapsed         | 58         |\n",
                        "|    total_timesteps      | 4096       |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.10763698 |\n",
                        "|    clip_fraction        | 0.00176    |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -0.136     |\n",
                        "|    explained_variance   | 0.000107   |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 1.37       |\n",
                        "|    n_updates            | 70         |\n",
                        "|    policy_gradient_loss | -0.00015   |\n",
                        "|    value_loss           | 2.31       |\n",
                        "----------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 375        |\n",
                        "|    ep_rew_mean          | -35.1      |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 69         |\n",
                        "|    iterations           | 9          |\n",
                        "|    time_elapsed         | 66         |\n",
                        "|    total_timesteps      | 4608       |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.45753247 |\n",
                        "|    clip_fraction        | 0.0746     |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -0.161     |\n",
                        "|    explained_variance   | 0          |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 0.0337     |\n",
                        "|    n_updates            | 80         |\n",
                        "|    policy_gradient_loss | 0.0144     |\n",
                        "|    value_loss           | 0.244      |\n",
                        "----------------------------------------\n",
                        "------------------------------------------\n",
                        "| rollout/                |              |\n",
                        "|    ep_len_mean          | 483          |\n",
                        "|    ep_rew_mean          | -35.7        |\n",
                        "| time/                   |              |\n",
                        "|    fps                  | 69           |\n",
                        "|    iterations           | 10           |\n",
                        "|    time_elapsed         | 73           |\n",
                        "|    total_timesteps      | 5120         |\n",
                        "| train/                  |              |\n",
                        "|    approx_kl            | 0.0090479115 |\n",
                        "|    clip_fraction        | 0.00371      |\n",
                        "|    clip_range           | 0.2          |\n",
                        "|    entropy_loss         | -0.00325     |\n",
                        "|    explained_variance   | 0            |\n",
                        "|    learning_rate        | 0.01         |\n",
                        "|    loss                 | 2.83         |\n",
                        "|    n_updates            | 90           |\n",
                        "|    policy_gradient_loss | 0.00102      |\n",
                        "|    value_loss           | 2.79         |\n",
                        "------------------------------------------\n",
                        "-------------------------------------------\n",
                        "| rollout/                |               |\n",
                        "|    ep_len_mean          | 483           |\n",
                        "|    ep_rew_mean          | -35.7         |\n",
                        "| time/                   |               |\n",
                        "|    fps                  | 69            |\n",
                        "|    iterations           | 11            |\n",
                        "|    time_elapsed         | 81            |\n",
                        "|    total_timesteps      | 5632          |\n",
                        "| train/                  |               |\n",
                        "|    approx_kl            | 2.6472844e-07 |\n",
                        "|    clip_fraction        | 0             |\n",
                        "|    clip_range           | 0.2           |\n",
                        "|    entropy_loss         | -0.00954      |\n",
                        "|    explained_variance   | 0.000187      |\n",
                        "|    learning_rate        | 0.01          |\n",
                        "|    loss                 | 0.419         |\n",
                        "|    n_updates            | 100           |\n",
                        "|    policy_gradient_loss | 3.64e-07      |\n",
                        "|    value_loss           | 1.51          |\n",
                        "-------------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 551         |\n",
                        "|    ep_rew_mean          | -36.3       |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 69          |\n",
                        "|    iterations           | 12          |\n",
                        "|    time_elapsed         | 88          |\n",
                        "|    total_timesteps      | 6144        |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.001246178 |\n",
                        "|    clip_fraction        | 0.00176     |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.0133     |\n",
                        "|    explained_variance   | 0           |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 0.289       |\n",
                        "|    n_updates            | 110         |\n",
                        "|    policy_gradient_loss | -9.35e-05   |\n",
                        "|    value_loss           | 0.535       |\n",
                        "-----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 551         |\n",
                        "|    ep_rew_mean          | -36.3       |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 69          |\n",
                        "|    iterations           | 13          |\n",
                        "|    time_elapsed         | 95          |\n",
                        "|    total_timesteps      | 6656        |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.012861948 |\n",
                        "|    clip_fraction        | 0.00137     |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.0412     |\n",
                        "|    explained_variance   | 0.000148    |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 3.86        |\n",
                        "|    n_updates            | 120         |\n",
                        "|    policy_gradient_loss | 5.6e-06     |\n",
                        "|    value_loss           | 6.29        |\n",
                        "-----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 551         |\n",
                        "|    ep_rew_mean          | -36.3       |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 69          |\n",
                        "|    iterations           | 14          |\n",
                        "|    time_elapsed         | 102         |\n",
                        "|    total_timesteps      | 7168        |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.019650271 |\n",
                        "|    clip_fraction        | 0.00371     |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.00754    |\n",
                        "|    explained_variance   | -1.19e-07   |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 0.0682      |\n",
                        "|    n_updates            | 130         |\n",
                        "|    policy_gradient_loss | -0.000566   |\n",
                        "|    value_loss           | 0.124       |\n",
                        "-----------------------------------------\n",
                        "---------------------------------------\n",
                        "| rollout/                |           |\n",
                        "|    ep_len_mean          | 604       |\n",
                        "|    ep_rew_mean          | -36.8     |\n",
                        "| time/                   |           |\n",
                        "|    fps                  | 69        |\n",
                        "|    iterations           | 15        |\n",
                        "|    time_elapsed         | 110       |\n",
                        "|    total_timesteps      | 7680      |\n",
                        "| train/                  |           |\n",
                        "|    approx_kl            | 0.0       |\n",
                        "|    clip_fraction        | 0         |\n",
                        "|    clip_range           | 0.2       |\n",
                        "|    entropy_loss         | -0.000701 |\n",
                        "|    explained_variance   | 5.96e-08  |\n",
                        "|    learning_rate        | 0.01      |\n",
                        "|    loss                 | 1.17      |\n",
                        "|    n_updates            | 140       |\n",
                        "|    policy_gradient_loss | 2.31e-09  |\n",
                        "|    value_loss           | 3.7       |\n",
                        "---------------------------------------\n",
                        "------------------------------------------\n",
                        "| rollout/                |              |\n",
                        "|    ep_len_mean          | 604          |\n",
                        "|    ep_rew_mean          | -36.8        |\n",
                        "| time/                   |              |\n",
                        "|    fps                  | 69           |\n",
                        "|    iterations           | 16           |\n",
                        "|    time_elapsed         | 117          |\n",
                        "|    total_timesteps      | 8192         |\n",
                        "| train/                  |              |\n",
                        "|    approx_kl            | 7.799827e-09 |\n",
                        "|    clip_fraction        | 0            |\n",
                        "|    clip_range           | 0.2          |\n",
                        "|    entropy_loss         | -0.000871    |\n",
                        "|    explained_variance   | 0.00032      |\n",
                        "|    learning_rate        | 0.01         |\n",
                        "|    loss                 | 0.33         |\n",
                        "|    n_updates            | 150          |\n",
                        "|    policy_gradient_loss | 1.96e-08     |\n",
                        "|    value_loss           | 1.84         |\n",
                        "------------------------------------------\n",
                        "-------------------------------------------\n",
                        "| rollout/                |               |\n",
                        "|    ep_len_mean          | 665           |\n",
                        "|    ep_rew_mean          | -36           |\n",
                        "| time/                   |               |\n",
                        "|    fps                  | 69            |\n",
                        "|    iterations           | 17            |\n",
                        "|    time_elapsed         | 124           |\n",
                        "|    total_timesteps      | 8704          |\n",
                        "| train/                  |               |\n",
                        "|    approx_kl            | 3.7252903e-08 |\n",
                        "|    clip_fraction        | 0             |\n",
                        "|    clip_range           | 0.2           |\n",
                        "|    entropy_loss         | -0.00172      |\n",
                        "|    explained_variance   | 5.96e-08      |\n",
                        "|    learning_rate        | 0.01          |\n",
                        "|    loss                 | 0.574         |\n",
                        "|    n_updates            | 160           |\n",
                        "|    policy_gradient_loss | 8.38e-10      |\n",
                        "|    value_loss           | 0.948         |\n",
                        "-------------------------------------------\n",
                        "-------------------------------------------\n",
                        "| rollout/                |               |\n",
                        "|    ep_len_mean          | 665           |\n",
                        "|    ep_rew_mean          | -36           |\n",
                        "| time/                   |               |\n",
                        "|    fps                  | 69            |\n",
                        "|    iterations           | 18            |\n",
                        "|    time_elapsed         | 132           |\n",
                        "|    total_timesteps      | 9216          |\n",
                        "| train/                  |               |\n",
                        "|    approx_kl            | 2.2933818e-08 |\n",
                        "|    clip_fraction        | 0             |\n",
                        "|    clip_range           | 0.2           |\n",
                        "|    entropy_loss         | -0.00245      |\n",
                        "|    explained_variance   | 0.000572      |\n",
                        "|    learning_rate        | 0.01          |\n",
                        "|    loss                 | 0.144         |\n",
                        "|    n_updates            | 170           |\n",
                        "|    policy_gradient_loss | -1.89e-07     |\n",
                        "|    value_loss           | 0.327         |\n",
                        "-------------------------------------------\n",
                        "-------------------------------------------\n",
                        "| rollout/                |               |\n",
                        "|    ep_len_mean          | 665           |\n",
                        "|    ep_rew_mean          | -36           |\n",
                        "| time/                   |               |\n",
                        "|    fps                  | 69            |\n",
                        "|    iterations           | 19            |\n",
                        "|    time_elapsed         | 139           |\n",
                        "|    total_timesteps      | 9728          |\n",
                        "| train/                  |               |\n",
                        "|    approx_kl            | 2.3916364e-06 |\n",
                        "|    clip_fraction        | 0             |\n",
                        "|    clip_range           | 0.2           |\n",
                        "|    entropy_loss         | -0.0197       |\n",
                        "|    explained_variance   | 5.96e-08      |\n",
                        "|    learning_rate        | 0.01          |\n",
                        "|    loss                 | 0.00907       |\n",
                        "|    n_updates            | 180           |\n",
                        "|    policy_gradient_loss | 3.73e-09      |\n",
                        "|    value_loss           | 0.0275        |\n",
                        "-------------------------------------------\n",
                        "------------------------------------------\n",
                        "| rollout/                |              |\n",
                        "|    ep_len_mean          | 723          |\n",
                        "|    ep_rew_mean          | -35.7        |\n",
                        "| time/                   |              |\n",
                        "|    fps                  | 69           |\n",
                        "|    iterations           | 20           |\n",
                        "|    time_elapsed         | 147          |\n",
                        "|    total_timesteps      | 10240        |\n",
                        "| train/                  |              |\n",
                        "|    approx_kl            | 0.0126755815 |\n",
                        "|    clip_fraction        | 0.00332      |\n",
                        "|    clip_range           | 0.2          |\n",
                        "|    entropy_loss         | -0.0674      |\n",
                        "|    explained_variance   | 1.19e-07     |\n",
                        "|    learning_rate        | 0.01         |\n",
                        "|    loss                 | 0.201        |\n",
                        "|    n_updates            | 190          |\n",
                        "|    policy_gradient_loss | -0.000223    |\n",
                        "|    value_loss           | 0.33         |\n",
                        "------------------------------------------\n",
                        "---------------------------------------\n",
                        "| rollout/                |           |\n",
                        "|    ep_len_mean          | 723       |\n",
                        "|    ep_rew_mean          | -35.7     |\n",
                        "| time/                   |           |\n",
                        "|    fps                  | 69        |\n",
                        "|    iterations           | 21        |\n",
                        "|    time_elapsed         | 155       |\n",
                        "|    total_timesteps      | 10752     |\n",
                        "| train/                  |           |\n",
                        "|    approx_kl            | 0.2177256 |\n",
                        "|    clip_fraction        | 0.0363    |\n",
                        "|    clip_range           | 0.2       |\n",
                        "|    entropy_loss         | -0.164    |\n",
                        "|    explained_variance   | -0.0074   |\n",
                        "|    learning_rate        | 0.01      |\n",
                        "|    loss                 | 0.365     |\n",
                        "|    n_updates            | 200       |\n",
                        "|    policy_gradient_loss | 0.0037    |\n",
                        "|    value_loss           | 2.83      |\n",
                        "---------------------------------------\n",
                        "-------------------------------------------\n",
                        "| rollout/                |               |\n",
                        "|    ep_len_mean          | 723           |\n",
                        "|    ep_rew_mean          | -35.7         |\n",
                        "| time/                   |               |\n",
                        "|    fps                  | 69            |\n",
                        "|    iterations           | 22            |\n",
                        "|    time_elapsed         | 162           |\n",
                        "|    total_timesteps      | 11264         |\n",
                        "| train/                  |               |\n",
                        "|    approx_kl            | 5.5879354e-07 |\n",
                        "|    clip_fraction        | 0             |\n",
                        "|    clip_range           | 0.2           |\n",
                        "|    entropy_loss         | -0.00286      |\n",
                        "|    explained_variance   | 0             |\n",
                        "|    learning_rate        | 0.01          |\n",
                        "|    loss                 | 0.0349        |\n",
                        "|    n_updates            | 210           |\n",
                        "|    policy_gradient_loss | -8.67e-09     |\n",
                        "|    value_loss           | 0.215         |\n",
                        "-------------------------------------------\n",
                        "-------------------------------------------\n",
                        "| rollout/                |               |\n",
                        "|    ep_len_mean          | 772           |\n",
                        "|    ep_rew_mean          | -36.1         |\n",
                        "| time/                   |               |\n",
                        "|    fps                  | 69            |\n",
                        "|    iterations           | 23            |\n",
                        "|    time_elapsed         | 169           |\n",
                        "|    total_timesteps      | 11776         |\n",
                        "| train/                  |               |\n",
                        "|    approx_kl            | 0.00014328212 |\n",
                        "|    clip_fraction        | 0             |\n",
                        "|    clip_range           | 0.2           |\n",
                        "|    entropy_loss         | -0.0501       |\n",
                        "|    explained_variance   | 1.19e-07      |\n",
                        "|    learning_rate        | 0.01          |\n",
                        "|    loss                 | 0.498         |\n",
                        "|    n_updates            | 220           |\n",
                        "|    policy_gradient_loss | -6.05e-10     |\n",
                        "|    value_loss           | 1.12          |\n",
                        "-------------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 772         |\n",
                        "|    ep_rew_mean          | -36.1       |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 69          |\n",
                        "|    iterations           | 24          |\n",
                        "|    time_elapsed         | 176         |\n",
                        "|    total_timesteps      | 12288       |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.038443573 |\n",
                        "|    clip_fraction        | 0.0779      |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.229      |\n",
                        "|    explained_variance   | -0.0502     |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 1.52        |\n",
                        "|    n_updates            | 230         |\n",
                        "|    policy_gradient_loss | -0.00511    |\n",
                        "|    value_loss           | 2.93        |\n",
                        "-----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 772         |\n",
                        "|    ep_rew_mean          | -36.1       |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 69          |\n",
                        "|    iterations           | 25          |\n",
                        "|    time_elapsed         | 184         |\n",
                        "|    total_timesteps      | 12800       |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.021960888 |\n",
                        "|    clip_fraction        | 0.0131      |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.148      |\n",
                        "|    explained_variance   | 0           |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 0.616       |\n",
                        "|    n_updates            | 240         |\n",
                        "|    policy_gradient_loss | 0.000498    |\n",
                        "|    value_loss           | 0.52        |\n",
                        "-----------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 772        |\n",
                        "|    ep_rew_mean          | -36.1      |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 69         |\n",
                        "|    iterations           | 26         |\n",
                        "|    time_elapsed         | 191        |\n",
                        "|    total_timesteps      | 13312      |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.03342314 |\n",
                        "|    clip_fraction        | 0.0197     |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -0.199     |\n",
                        "|    explained_variance   | 0          |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 1.47       |\n",
                        "|    n_updates            | 250        |\n",
                        "|    policy_gradient_loss | -0.000219  |\n",
                        "|    value_loss           | 1.84       |\n",
                        "----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 832         |\n",
                        "|    ep_rew_mean          | -36.3       |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 69          |\n",
                        "|    iterations           | 27          |\n",
                        "|    time_elapsed         | 198         |\n",
                        "|    total_timesteps      | 13824       |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.010438811 |\n",
                        "|    clip_fraction        | 0.0301      |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.156      |\n",
                        "|    explained_variance   | 0           |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 0.344       |\n",
                        "|    n_updates            | 260         |\n",
                        "|    policy_gradient_loss | 0.00155     |\n",
                        "|    value_loss           | 0.811       |\n",
                        "-----------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 832        |\n",
                        "|    ep_rew_mean          | -36.3      |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 69         |\n",
                        "|    iterations           | 28         |\n",
                        "|    time_elapsed         | 205        |\n",
                        "|    total_timesteps      | 14336      |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.09697966 |\n",
                        "|    clip_fraction        | 0.162      |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -0.542     |\n",
                        "|    explained_variance   | 0.623      |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 0.0343     |\n",
                        "|    n_updates            | 270        |\n",
                        "|    policy_gradient_loss | 0.000355   |\n",
                        "|    value_loss           | 0.0909     |\n",
                        "----------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 832        |\n",
                        "|    ep_rew_mean          | -36.3      |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 69         |\n",
                        "|    iterations           | 29         |\n",
                        "|    time_elapsed         | 213        |\n",
                        "|    total_timesteps      | 14848      |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.00569186 |\n",
                        "|    clip_fraction        | 0.152      |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -0.685     |\n",
                        "|    explained_variance   | 1.19e-07   |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 0.452      |\n",
                        "|    n_updates            | 280        |\n",
                        "|    policy_gradient_loss | 0.00824    |\n",
                        "|    value_loss           | 1.3        |\n",
                        "----------------------------------------\n",
                        "------------------------------------------\n",
                        "| rollout/                |              |\n",
                        "|    ep_len_mean          | 832          |\n",
                        "|    ep_rew_mean          | -36.3        |\n",
                        "| time/                   |              |\n",
                        "|    fps                  | 69           |\n",
                        "|    iterations           | 30           |\n",
                        "|    time_elapsed         | 222          |\n",
                        "|    total_timesteps      | 15360        |\n",
                        "| train/                  |              |\n",
                        "|    approx_kl            | 0.0093615465 |\n",
                        "|    clip_fraction        | 0.0768       |\n",
                        "|    clip_range           | 0.2          |\n",
                        "|    entropy_loss         | -0.754       |\n",
                        "|    explained_variance   | 0            |\n",
                        "|    learning_rate        | 0.01         |\n",
                        "|    loss                 | 0.149        |\n",
                        "|    n_updates            | 290          |\n",
                        "|    policy_gradient_loss | 0.00215      |\n",
                        "|    value_loss           | 0.228        |\n",
                        "------------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 906         |\n",
                        "|    ep_rew_mean          | -36.9       |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 69          |\n",
                        "|    iterations           | 31          |\n",
                        "|    time_elapsed         | 229         |\n",
                        "|    total_timesteps      | 15872       |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.011592602 |\n",
                        "|    clip_fraction        | 0.0689      |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.805      |\n",
                        "|    explained_variance   | 1.19e-07    |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 0.485       |\n",
                        "|    n_updates            | 300         |\n",
                        "|    policy_gradient_loss | -0.00269    |\n",
                        "|    value_loss           | 0.893       |\n",
                        "-----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 906         |\n",
                        "|    ep_rew_mean          | -36.9       |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 69          |\n",
                        "|    iterations           | 32          |\n",
                        "|    time_elapsed         | 236         |\n",
                        "|    total_timesteps      | 16384       |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.043214045 |\n",
                        "|    clip_fraction        | 0.208       |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.997      |\n",
                        "|    explained_variance   | 0.147       |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 0.105       |\n",
                        "|    n_updates            | 310         |\n",
                        "|    policy_gradient_loss | -0.0268     |\n",
                        "|    value_loss           | 0.36        |\n",
                        "-----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 906         |\n",
                        "|    ep_rew_mean          | -36.9       |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 69          |\n",
                        "|    iterations           | 33          |\n",
                        "|    time_elapsed         | 244         |\n",
                        "|    total_timesteps      | 16896       |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.005073509 |\n",
                        "|    clip_fraction        | 0.0547      |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -1.02       |\n",
                        "|    explained_variance   | 0           |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 0.0239      |\n",
                        "|    n_updates            | 320         |\n",
                        "|    policy_gradient_loss | 0.00195     |\n",
                        "|    value_loss           | 0.0524      |\n",
                        "-----------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 950        |\n",
                        "|    ep_rew_mean          | -38        |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 69         |\n",
                        "|    iterations           | 34         |\n",
                        "|    time_elapsed         | 251        |\n",
                        "|    total_timesteps      | 17408      |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.04409171 |\n",
                        "|    clip_fraction        | 0.276      |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -1.14      |\n",
                        "|    explained_variance   | 0.0145     |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 1.25       |\n",
                        "|    n_updates            | 330        |\n",
                        "|    policy_gradient_loss | -0.0067    |\n",
                        "|    value_loss           | 3.09       |\n",
                        "----------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 950        |\n",
                        "|    ep_rew_mean          | -38        |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 69         |\n",
                        "|    iterations           | 35         |\n",
                        "|    time_elapsed         | 258        |\n",
                        "|    total_timesteps      | 17920      |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.03742821 |\n",
                        "|    clip_fraction        | 0.22       |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -1.13      |\n",
                        "|    explained_variance   | 0.25       |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 0.599      |\n",
                        "|    n_updates            | 340        |\n",
                        "|    policy_gradient_loss | 0.0077     |\n",
                        "|    value_loss           | 3.99       |\n",
                        "----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 950         |\n",
                        "|    ep_rew_mean          | -38         |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 69          |\n",
                        "|    iterations           | 36          |\n",
                        "|    time_elapsed         | 266         |\n",
                        "|    total_timesteps      | 18432       |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.057511322 |\n",
                        "|    clip_fraction        | 0.366       |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -1.25       |\n",
                        "|    explained_variance   | 0.851       |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 0.0328      |\n",
                        "|    n_updates            | 350         |\n",
                        "|    policy_gradient_loss | -0.0278     |\n",
                        "|    value_loss           | 0.112       |\n",
                        "-----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 950         |\n",
                        "|    ep_rew_mean          | -38         |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 69          |\n",
                        "|    iterations           | 37          |\n",
                        "|    time_elapsed         | 273         |\n",
                        "|    total_timesteps      | 18944       |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.009398313 |\n",
                        "|    clip_fraction        | 0.155       |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.97       |\n",
                        "|    explained_variance   | -1.19e-07   |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 0.057       |\n",
                        "|    n_updates            | 360         |\n",
                        "|    policy_gradient_loss | -0.00469    |\n",
                        "|    value_loss           | 0.114       |\n",
                        "-----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 950         |\n",
                        "|    ep_rew_mean          | -38         |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 69          |\n",
                        "|    iterations           | 38          |\n",
                        "|    time_elapsed         | 280         |\n",
                        "|    total_timesteps      | 19456       |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.008429136 |\n",
                        "|    clip_fraction        | 0.0883      |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.95       |\n",
                        "|    explained_variance   | 0           |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 0.285       |\n",
                        "|    n_updates            | 370         |\n",
                        "|    policy_gradient_loss | -0.00214    |\n",
                        "|    value_loss           | 0.235       |\n",
                        "-----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 950         |\n",
                        "|    ep_rew_mean          | -38         |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 69          |\n",
                        "|    iterations           | 39          |\n",
                        "|    time_elapsed         | 287         |\n",
                        "|    total_timesteps      | 19968       |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.009792345 |\n",
                        "|    clip_fraction        | 0.0732      |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.956      |\n",
                        "|    explained_variance   | 1.19e-07    |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 0.0634      |\n",
                        "|    n_updates            | 380         |\n",
                        "|    policy_gradient_loss | 0.00171     |\n",
                        "|    value_loss           | 0.143       |\n",
                        "-----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 950         |\n",
                        "|    ep_rew_mean          | -38         |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 69          |\n",
                        "|    iterations           | 40          |\n",
                        "|    time_elapsed         | 294         |\n",
                        "|    total_timesteps      | 20480       |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.007278698 |\n",
                        "|    clip_fraction        | 0.103       |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -1.11       |\n",
                        "|    explained_variance   | 0           |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 0.0279      |\n",
                        "|    n_updates            | 390         |\n",
                        "|    policy_gradient_loss | -0.000956   |\n",
                        "|    value_loss           | 0.227       |\n",
                        "-----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 950         |\n",
                        "|    ep_rew_mean          | -38         |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 69          |\n",
                        "|    iterations           | 41          |\n",
                        "|    time_elapsed         | 302         |\n",
                        "|    total_timesteps      | 20992       |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.020858988 |\n",
                        "|    clip_fraction        | 0.157       |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.953      |\n",
                        "|    explained_variance   | 0           |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 0.0213      |\n",
                        "|    n_updates            | 400         |\n",
                        "|    policy_gradient_loss | -0.00444    |\n",
                        "|    value_loss           | 0.0543      |\n",
                        "-----------------------------------------\n",
                        "------------------------------------------\n",
                        "| rollout/                |              |\n",
                        "|    ep_len_mean          | 950          |\n",
                        "|    ep_rew_mean          | -38          |\n",
                        "| time/                   |              |\n",
                        "|    fps                  | 69           |\n",
                        "|    iterations           | 42           |\n",
                        "|    time_elapsed         | 309          |\n",
                        "|    total_timesteps      | 21504        |\n",
                        "| train/                  |              |\n",
                        "|    approx_kl            | 0.0033000247 |\n",
                        "|    clip_fraction        | 0.0811       |\n",
                        "|    clip_range           | 0.2          |\n",
                        "|    entropy_loss         | -0.989       |\n",
                        "|    explained_variance   | -1.19e-07    |\n",
                        "|    learning_rate        | 0.01         |\n",
                        "|    loss                 | 0.0703       |\n",
                        "|    n_updates            | 410          |\n",
                        "|    policy_gradient_loss | -0.000213    |\n",
                        "|    value_loss           | 0.441        |\n",
                        "------------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 950         |\n",
                        "|    ep_rew_mean          | -38         |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 69          |\n",
                        "|    iterations           | 43          |\n",
                        "|    time_elapsed         | 316         |\n",
                        "|    total_timesteps      | 22016       |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.004823655 |\n",
                        "|    clip_fraction        | 0.124       |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -1.08       |\n",
                        "|    explained_variance   | -1.19e-07   |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 0.0469      |\n",
                        "|    n_updates            | 420         |\n",
                        "|    policy_gradient_loss | -0.00413    |\n",
                        "|    value_loss           | 0.0769      |\n",
                        "-----------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 950        |\n",
                        "|    ep_rew_mean          | -38        |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 69         |\n",
                        "|    iterations           | 44         |\n",
                        "|    time_elapsed         | 323        |\n",
                        "|    total_timesteps      | 22528      |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.01071211 |\n",
                        "|    clip_fraction        | 0.218      |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -1.12      |\n",
                        "|    explained_variance   | 0          |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 0.0237     |\n",
                        "|    n_updates            | 430        |\n",
                        "|    policy_gradient_loss | -0.00998   |\n",
                        "|    value_loss           | 0.068      |\n",
                        "----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 950         |\n",
                        "|    ep_rew_mean          | -38         |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 69          |\n",
                        "|    iterations           | 45          |\n",
                        "|    time_elapsed         | 330         |\n",
                        "|    total_timesteps      | 23040       |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.012237855 |\n",
                        "|    clip_fraction        | 0.191       |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -1.1        |\n",
                        "|    explained_variance   | 0           |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 0.614       |\n",
                        "|    n_updates            | 440         |\n",
                        "|    policy_gradient_loss | -0.00827    |\n",
                        "|    value_loss           | 0.954       |\n",
                        "-----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 1.22e+03    |\n",
                        "|    ep_rew_mean          | -38.4       |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 69          |\n",
                        "|    iterations           | 46          |\n",
                        "|    time_elapsed         | 338         |\n",
                        "|    total_timesteps      | 23552       |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.029397734 |\n",
                        "|    clip_fraction        | 0.278       |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -1.01       |\n",
                        "|    explained_variance   | 0           |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 0.231       |\n",
                        "|    n_updates            | 450         |\n",
                        "|    policy_gradient_loss | -0.0124     |\n",
                        "|    value_loss           | 0.803       |\n",
                        "-----------------------------------------\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\Jyao7\\miniconda3\\envs\\gpuenv\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    301\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    307\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\Jyao7\\miniconda3\\envs\\gpuenv\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:250\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    247\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 250\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\Jyao7\\miniconda3\\envs\\gpuenv\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:178\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, spaces\u001b[38;5;241m.\u001b[39mBox):\n\u001b[0;32m    176\u001b[0m     clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[1;32m--> 178\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\Jyao7\\miniconda3\\envs\\gpuenv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:163\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\Jyao7\\miniconda3\\envs\\gpuenv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_transpose.py:95\u001b[0m, in \u001b[0;36mVecTransposeImage.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m---> 95\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# Transpose the terminal observations\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, done \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dones):\n",
                        "File \u001b[1;32mc:\\Users\\Jyao7\\miniconda3\\envs\\gpuenv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_frame_stack.py:33\u001b[0m, in \u001b[0;36mVecFrameStack.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     32\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[np\u001b[38;5;241m.\u001b[39mndarray, Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]], np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mndarray, List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]],]:\n\u001b[1;32m---> 33\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     observations, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstacked_obs\u001b[38;5;241m.\u001b[39mupdate(observations, dones, infos)\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m observations, rewards, dones, infos\n",
                        "File \u001b[1;32mc:\\Users\\Jyao7\\miniconda3\\envs\\gpuenv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:54\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 54\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx]:\n\u001b[0;32m     58\u001b[0m             \u001b[38;5;66;03m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[0;32m     59\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n",
                        "File \u001b[1;32mc:\\Users\\Jyao7\\miniconda3\\envs\\gpuenv\\lib\\site-packages\\gym\\core.py:323\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m--> 323\u001b[0m     observation, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(observation), reward, done, info\n",
                        "File \u001b[1;32mc:\\Users\\Jyao7\\miniconda3\\envs\\gpuenv\\lib\\site-packages\\gym\\core.py:324\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m    323\u001b[0m     observation, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m--> 324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m, reward, done, info\n",
                        "File \u001b[1;32mc:\\Users\\Jyao7\\miniconda3\\envs\\gpuenv\\lib\\site-packages\\gym\\wrappers\\gray_scale_observation.py:31\u001b[0m, in \u001b[0;36mGrayScaleObservation.observation\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobservation\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation):\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_RGB2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_dim:\n\u001b[0;32m     33\u001b[0m         observation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(observation, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "model.learn(total_timesteps=100000, callback=callback)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
                        "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
                        "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
                        "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
                    ]
                }
            ],
            "source": [
                "model = PPO.load('./train/best_model_20000')\n",
                "#env = TetrisSingleEnv()\n",
                "state = env.reset()\n",
                "i = 0\n",
                "\n",
                "while True:\n",
                "    if (i >= 1000):\n",
                "        env.close()\n",
                "        break\n",
                "    action, _ = model.predict(state)\n",
                "    state, reward, done, info = env.step(action)\n",
                "    env.render()\n",
                "    i += 1"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
