{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "pygame 2.5.2 (SDL 2.28.3, Python 3.10.13)\n",
                        "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import sys\n",
                "import matplotlib.pyplot as plt\n",
                "import gym\n",
                "\n",
                "sys.path.insert(0, './TetrisEnv')\n",
                "from TetrisBattle.envs.tetris_env import TetrisSingleEnv, TetrisEnv\n",
                "from TetrisBattle import *\n",
                "from Model.Feature_Extraction import TetrisActorCriticCnnPolicyLookAhead\n",
                "# %pip install -e ./TetrisEnv\n",
                "# import TetrisBattle"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class InputGetter():\n",
                "    def __init__(self):\n",
                "        self.input_log = []\n",
                "        \n",
                "    def get_input(self):\n",
                "        while True:\n",
                "            try:\n",
                "                if len(self.input_log) == 0:\n",
                "                    self.input_log = [*input(\">\")]\n",
                "                \n",
                "                inp = self.input_log.pop(0)\n",
                "                inp = int(inp)\n",
                "                assert(inp in [0, 1, 2, 3, 4, 5, 6, 7, 9])\n",
                "                return inp\n",
                "            except Exception as e:\n",
                "                print(e)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "env = TetrisSingleEnv(obs_type=\"lookahead\")\n",
                "env.reset()\n",
                "env.render()\n",
                "i = 0\n",
                "inputter = InputGetter()\n",
                "while True:\n",
                "    action = inputter.get_input()\n",
                "    if action == 9:\n",
                "        env.close()\n",
                "        break\n",
                "    state, reward, done, info = env.step(env.action_space.sample())\n",
                "    # print(\"infow\", info)\n",
                "    # print(\"rewrd\",reward)\n",
                "    env.render()\n",
                "    print(state.shape)\n",
                "    print(list(state))\n",
                "    # print(env.game_interface.get_obs().shape)\n",
                "    grid = env.game_interface.get_obs()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(10, 880, 1)"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "state.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from Model.Feature_Extraction import TetisFeatureExtractorLookAhead\n",
                "fe = TetisFeatureExtractorLookAhead(env.observation_space)\n",
                "# fe(grid[None])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "env = TetrisSingleEnv()\n",
                "i = 0\n",
                "inputter = InputGetter()\n",
                "while True:\n",
                "    action = inputter.get_input()\n",
                "    if action == 9:\n",
                "        env.close()\n",
                "        break\n",
                "    state, reward, done, info = env.og_step(action)\n",
                "    print(\"infow\", info)\n",
                "    print(\"rewrd\",reward)\n",
                "    env.render()\n",
                "    print(env.get_obs())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# env = make('SinglePTetris-v0')\n",
                "env = TetrisSingleEnv()\n",
                "ob = env.reset()\n",
                "dots = np.ones((20, 10))\n",
                "x = 100\n",
                "y = 130\n",
                "ob[x:x+10,y:y+10] = [255,255,255]\n",
                "plt.imshow(ob, cmap=\"plasma\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from shimmy.openai_gym_compatibility import _convert_space\n",
                "lh_env = TetrisSingleEnv(obs_type=\"lookahead\")\n",
                "g_env = TetrisSingleEnv(obs_type=\"grid\")\n",
                "\n",
                "gs = g_env.reset()\n",
                "ls = lh_env.reset()\n",
                "print(gs.shape, type(gs))\n",
                "print(ls.shape, type(ls))\n",
                "# # _convert_space(g_env.observation_space)\n",
                "# # _convert_space(lh_env.observation_space)\n",
                "# # print(g_env.observation_space)\n",
                "# print(lh_env.observation_space)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "libpng warning: iCCP: known incorrect sRGB profile\n",
                        "libpng warning: iCCP: known incorrect sRGB profile\n",
                        "libpng warning: iCCP: known incorrect sRGB profile\n",
                        "libpng warning: iCCP: known incorrect sRGB profile\n",
                        "libpng warning: iCCP: known incorrect sRGB profile\n",
                        "libpng warning: iCCP: known incorrect sRGB profile\n",
                        "libpng warning: iCCP: known incorrect sRGB profile\n",
                        "libpng warning: iCCP: known incorrect sRGB profile\n",
                        "libpng warning: iCCP: known incorrect sRGB profile\n",
                        "libpng warning: iCCP: known incorrect sRGB profile\n",
                        "libpng warning: iCCP: known incorrect sRGB profile\n",
                        "libpng warning: iCCP: known incorrect sRGB profile\n",
                        "libpng warning: iCCP: known incorrect sRGB profile\n",
                        "libpng warning: iCCP: known incorrect sRGB profile\n",
                        "libpng warning: iCCP: known incorrect sRGB profile\n",
                        "libpng warning: iCCP: known incorrect sRGB profile\n",
                        "libpng warning: iCCP: known incorrect sRGB profile\n",
                        "/opt/miniconda3/envs/ECE_113_Capstone_1/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
                        "  warnings.warn(\n"
                    ]
                }
            ],
            "source": [
                "from gym.wrappers import GrayScaleObservation\n",
                "from preprocessing.EensyWeensy import MakeEensyWeensy\n",
                "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
                "# from gym import make\n",
                "\n",
                "naked_env = TetrisSingleEnv(obs_type=\"lookahead\")\n",
                "# env = GrayScaleObservation(env, keep_dim=True)\n",
                "# env = MakeEensyWeensy(env, cut_in_half=True, scale=.25)\n",
                "env = DummyVecEnv([lambda: naked_env])\n",
                "# env = VecFrameStack(env, 4, channels_order=\"last\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from Model.Feature_Extraction import TetisFeatureExtractor\n",
                "# feat_ex = TetisFeatureExtractor(gym.spaces.Box(0.0, 1.0, (20, 34), \"float32\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ob,_,_,_ = env.step([0])\n",
                "ob.transpose(3, 0, 1, 2).shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# for i in range(0, 1000):\n",
                "#     action = env.random_action()\n",
                "#     state, reward, done, info = env.step(action)\n",
                "#     env.render()\n",
                "#     i += 1\n",
                "# env.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "False\n"
                    ]
                }
            ],
            "source": [
                "import os \n",
                "from stable_baselines3 import PPO\n",
                "from stable_baselines3.common.callbacks import BaseCallback\n",
                "from stable_baselines3.common.env_checker import check_env\n",
                "import torch\n",
                "print(torch.cuda.is_available())\n",
                "# check_env(TetrisSingleEnv())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "class TrainAndLoggingCallback(BaseCallback):\n",
                "\n",
                "    def __init__(self, check_freq, save_path, verbose=1):\n",
                "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
                "        self.check_freq = check_freq\n",
                "        self.save_path = save_path\n",
                "\n",
                "    def _init_callback(self):\n",
                "        if self.save_path is not None:\n",
                "            os.makedirs(self.save_path, exist_ok=True)\n",
                "\n",
                "    def _on_step(self):\n",
                "        if self.n_calls % self.check_freq == 0:\n",
                "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
                "            self.model.save(model_path)\n",
                "\n",
                "        return True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "CHECKPOINT_DIR = './train/'\n",
                "LOG_DIR = './logs/'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using cpu device\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/miniconda3/envs/ECE_113_Capstone_1/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 32`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 32\n",
                        "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
                        "Info: (n_steps=32 and n_envs=1)\n",
                        "  warnings.warn(\n"
                    ]
                }
            ],
            "source": [
                "try:\n",
                "    del model\n",
                "except NameError:\n",
                "    pass\n",
                "model = PPO(TetrisActorCriticCnnPolicyLookAhead, env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=1e-2, n_steps=32, device=\"cuda\") \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Logging to ./logs/PPO_8\n",
                        "---------------------------------\n",
                        "| rollout/           |          |\n",
                        "|    ep_len_mean     | 22       |\n",
                        "|    ep_rew_mean     | -96.3    |\n",
                        "| time/              |          |\n",
                        "|    fps             | 8        |\n",
                        "|    iterations      | 1        |\n",
                        "|    time_elapsed    | 3        |\n",
                        "|    total_timesteps | 32       |\n",
                        "---------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 21         |\n",
                        "|    ep_rew_mean          | -102       |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 5          |\n",
                        "|    iterations           | 2          |\n",
                        "|    time_elapsed         | 10         |\n",
                        "|    total_timesteps      | 64         |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.40507835 |\n",
                        "|    clip_fraction        | 0.769      |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -3.69      |\n",
                        "|    explained_variance   | 0.0116     |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 444        |\n",
                        "|    n_updates            | 10         |\n",
                        "|    policy_gradient_loss | -0.145     |\n",
                        "|    value_loss           | 1.1e+03    |\n",
                        "----------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 21.8       |\n",
                        "|    ep_rew_mean          | -125       |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 5          |\n",
                        "|    iterations           | 3          |\n",
                        "|    time_elapsed         | 17         |\n",
                        "|    total_timesteps      | 96         |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.28269273 |\n",
                        "|    clip_fraction        | 0.628      |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -3.51      |\n",
                        "|    explained_variance   | 0          |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 274        |\n",
                        "|    n_updates            | 20         |\n",
                        "|    policy_gradient_loss | -0.0572    |\n",
                        "|    value_loss           | 682        |\n",
                        "----------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 22.6       |\n",
                        "|    ep_rew_mean          | -153       |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 4          |\n",
                        "|    iterations           | 4          |\n",
                        "|    time_elapsed         | 27         |\n",
                        "|    total_timesteps      | 128        |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.27507335 |\n",
                        "|    clip_fraction        | 0.581      |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -3.34      |\n",
                        "|    explained_variance   | 0          |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 856        |\n",
                        "|    n_updates            | 30         |\n",
                        "|    policy_gradient_loss | -0.0873    |\n",
                        "|    value_loss           | 1.92e+03   |\n",
                        "----------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 22.9       |\n",
                        "|    ep_rew_mean          | -170       |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 4          |\n",
                        "|    iterations           | 5          |\n",
                        "|    time_elapsed         | 34         |\n",
                        "|    total_timesteps      | 160        |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.09767949 |\n",
                        "|    clip_fraction        | 0.441      |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -3.17      |\n",
                        "|    explained_variance   | -1.19e-07  |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 4.42e+03   |\n",
                        "|    n_updates            | 40         |\n",
                        "|    policy_gradient_loss | -0.0466    |\n",
                        "|    value_loss           | 9.26e+03   |\n",
                        "----------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 22.1       |\n",
                        "|    ep_rew_mean          | -162       |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 4          |\n",
                        "|    iterations           | 6          |\n",
                        "|    time_elapsed         | 41         |\n",
                        "|    total_timesteps      | 192        |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.20459825 |\n",
                        "|    clip_fraction        | 0.65       |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -2.8       |\n",
                        "|    explained_variance   | 5.96e-08   |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 3.28e+03   |\n",
                        "|    n_updates            | 50         |\n",
                        "|    policy_gradient_loss | -0.0537    |\n",
                        "|    value_loss           | 6.98e+03   |\n",
                        "----------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 21.3       |\n",
                        "|    ep_rew_mean          | -152       |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 4          |\n",
                        "|    iterations           | 7          |\n",
                        "|    time_elapsed         | 47         |\n",
                        "|    total_timesteps      | 224        |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.37570715 |\n",
                        "|    clip_fraction        | 0.644      |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -2.58      |\n",
                        "|    explained_variance   | 0          |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 202        |\n",
                        "|    n_updates            | 60         |\n",
                        "|    policy_gradient_loss | -0.0606    |\n",
                        "|    value_loss           | 515        |\n",
                        "----------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 19.6       |\n",
                        "|    ep_rew_mean          | -136       |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 4          |\n",
                        "|    iterations           | 8          |\n",
                        "|    time_elapsed         | 54         |\n",
                        "|    total_timesteps      | 256        |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.32212552 |\n",
                        "|    clip_fraction        | 0.619      |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -2.47      |\n",
                        "|    explained_variance   | 0          |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 196        |\n",
                        "|    n_updates            | 70         |\n",
                        "|    policy_gradient_loss | -0.051     |\n",
                        "|    value_loss           | 487        |\n",
                        "----------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 19.6       |\n",
                        "|    ep_rew_mean          | -135       |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 4          |\n",
                        "|    iterations           | 9          |\n",
                        "|    time_elapsed         | 60         |\n",
                        "|    total_timesteps      | 288        |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.36079058 |\n",
                        "|    clip_fraction        | 0.503      |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -2.03      |\n",
                        "|    explained_variance   | 0          |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 53.1       |\n",
                        "|    n_updates            | 80         |\n",
                        "|    policy_gradient_loss | -0.0533    |\n",
                        "|    value_loss           | 153        |\n",
                        "----------------------------------------\n",
                        "---------------------------------------\n",
                        "| rollout/                |           |\n",
                        "|    ep_len_mean          | 17.1      |\n",
                        "|    ep_rew_mean          | -116      |\n",
                        "| time/                   |           |\n",
                        "|    fps                  | 4         |\n",
                        "|    iterations           | 10        |\n",
                        "|    time_elapsed         | 67        |\n",
                        "|    total_timesteps      | 320       |\n",
                        "| train/                  |           |\n",
                        "|    approx_kl            | 0.1745725 |\n",
                        "|    clip_fraction        | 0.416     |\n",
                        "|    clip_range           | 0.2       |\n",
                        "|    entropy_loss         | -1.82     |\n",
                        "|    explained_variance   | 0         |\n",
                        "|    learning_rate        | 0.01      |\n",
                        "|    loss                 | 87.5      |\n",
                        "|    n_updates            | 90        |\n",
                        "|    policy_gradient_loss | -0.0353   |\n",
                        "|    value_loss           | 245       |\n",
                        "---------------------------------------\n",
                        "---------------------------------------\n",
                        "| rollout/                |           |\n",
                        "|    ep_len_mean          | 16.4      |\n",
                        "|    ep_rew_mean          | -110      |\n",
                        "| time/                   |           |\n",
                        "|    fps                  | 4         |\n",
                        "|    iterations           | 11        |\n",
                        "|    time_elapsed         | 73        |\n",
                        "|    total_timesteps      | 352       |\n",
                        "| train/                  |           |\n",
                        "|    approx_kl            | 0.6876881 |\n",
                        "|    clip_fraction        | 0.5       |\n",
                        "|    clip_range           | 0.2       |\n",
                        "|    entropy_loss         | -1.32     |\n",
                        "|    explained_variance   | -1.19e-07 |\n",
                        "|    learning_rate        | 0.01      |\n",
                        "|    loss                 | 81.5      |\n",
                        "|    n_updates            | 100       |\n",
                        "|    policy_gradient_loss | -0.000151 |\n",
                        "|    value_loss           | 163       |\n",
                        "---------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 15.7       |\n",
                        "|    ep_rew_mean          | -106       |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 4          |\n",
                        "|    iterations           | 12         |\n",
                        "|    time_elapsed         | 79         |\n",
                        "|    total_timesteps      | 384        |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.35795128 |\n",
                        "|    clip_fraction        | 0.169      |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -0.867     |\n",
                        "|    explained_variance   | 0          |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 123        |\n",
                        "|    n_updates            | 110        |\n",
                        "|    policy_gradient_loss | -0.0197    |\n",
                        "|    value_loss           | 247        |\n",
                        "----------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 14.8       |\n",
                        "|    ep_rew_mean          | -100       |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 4          |\n",
                        "|    iterations           | 13         |\n",
                        "|    time_elapsed         | 84         |\n",
                        "|    total_timesteps      | 416        |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.20933454 |\n",
                        "|    clip_fraction        | 0.734      |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -0.389     |\n",
                        "|    explained_variance   | 0          |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 43.5       |\n",
                        "|    n_updates            | 120        |\n",
                        "|    policy_gradient_loss | -0.0132    |\n",
                        "|    value_loss           | 91.2       |\n",
                        "----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 14.1        |\n",
                        "|    ep_rew_mean          | -94.1       |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 4           |\n",
                        "|    iterations           | 14          |\n",
                        "|    time_elapsed         | 90          |\n",
                        "|    total_timesteps      | 448         |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.007444352 |\n",
                        "|    clip_fraction        | 0.05        |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.39       |\n",
                        "|    explained_variance   | -1.19e-07   |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 71          |\n",
                        "|    n_updates            | 130         |\n",
                        "|    policy_gradient_loss | 0.00229     |\n",
                        "|    value_loss           | 172         |\n",
                        "-----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 13.8        |\n",
                        "|    ep_rew_mean          | -91         |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 4           |\n",
                        "|    iterations           | 15          |\n",
                        "|    time_elapsed         | 97          |\n",
                        "|    total_timesteps      | 480         |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.022570275 |\n",
                        "|    clip_fraction        | 0.025       |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.429      |\n",
                        "|    explained_variance   | 0           |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 59.3        |\n",
                        "|    n_updates            | 140         |\n",
                        "|    policy_gradient_loss | -0.00334    |\n",
                        "|    value_loss           | 135         |\n",
                        "-----------------------------------------\n",
                        "-------------------------------------------\n",
                        "| rollout/                |               |\n",
                        "|    ep_len_mean          | 13.6          |\n",
                        "|    ep_rew_mean          | -89.5         |\n",
                        "| time/                   |               |\n",
                        "|    fps                  | 4             |\n",
                        "|    iterations           | 16            |\n",
                        "|    time_elapsed         | 104           |\n",
                        "|    total_timesteps      | 512           |\n",
                        "| train/                  |               |\n",
                        "|    approx_kl            | 4.9006194e-06 |\n",
                        "|    clip_fraction        | 0.241         |\n",
                        "|    clip_range           | 0.2           |\n",
                        "|    entropy_loss         | -0.635        |\n",
                        "|    explained_variance   | -1.19e-07     |\n",
                        "|    learning_rate        | 0.01          |\n",
                        "|    loss                 | 111           |\n",
                        "|    n_updates            | 150           |\n",
                        "|    policy_gradient_loss | -0.00811      |\n",
                        "|    value_loss           | 226           |\n",
                        "-------------------------------------------\n",
                        "----------------------------------------\n",
                        "| rollout/                |            |\n",
                        "|    ep_len_mean          | 13.2       |\n",
                        "|    ep_rew_mean          | -86.6      |\n",
                        "| time/                   |            |\n",
                        "|    fps                  | 4          |\n",
                        "|    iterations           | 17         |\n",
                        "|    time_elapsed         | 110        |\n",
                        "|    total_timesteps      | 544        |\n",
                        "| train/                  |            |\n",
                        "|    approx_kl            | 0.08555581 |\n",
                        "|    clip_fraction        | 0.419      |\n",
                        "|    clip_range           | 0.2        |\n",
                        "|    entropy_loss         | -0.666     |\n",
                        "|    explained_variance   | 0          |\n",
                        "|    learning_rate        | 0.01       |\n",
                        "|    loss                 | 47.4       |\n",
                        "|    n_updates            | 160        |\n",
                        "|    policy_gradient_loss | 0.0247     |\n",
                        "|    value_loss           | 105        |\n",
                        "----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 12.8        |\n",
                        "|    ep_rew_mean          | -83.9       |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 4           |\n",
                        "|    iterations           | 18          |\n",
                        "|    time_elapsed         | 116         |\n",
                        "|    total_timesteps      | 576         |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.054465137 |\n",
                        "|    clip_fraction        | 0.075       |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.305      |\n",
                        "|    explained_variance   | 0           |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 86.5        |\n",
                        "|    n_updates            | 170         |\n",
                        "|    policy_gradient_loss | -0.00543    |\n",
                        "|    value_loss           | 180         |\n",
                        "-----------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 12.4        |\n",
                        "|    ep_rew_mean          | -81.6       |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 4           |\n",
                        "|    iterations           | 19          |\n",
                        "|    time_elapsed         | 121         |\n",
                        "|    total_timesteps      | 608         |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.015960919 |\n",
                        "|    clip_fraction        | 0.075       |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.146      |\n",
                        "|    explained_variance   | 5.96e-08    |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 31.5        |\n",
                        "|    n_updates            | 180         |\n",
                        "|    policy_gradient_loss | -0.00563    |\n",
                        "|    value_loss           | 70.1        |\n",
                        "-----------------------------------------\n",
                        "------------------------------------------\n",
                        "| rollout/                |              |\n",
                        "|    ep_len_mean          | 12.2         |\n",
                        "|    ep_rew_mean          | -80.4        |\n",
                        "| time/                   |              |\n",
                        "|    fps                  | 5            |\n",
                        "|    iterations           | 20           |\n",
                        "|    time_elapsed         | 127          |\n",
                        "|    total_timesteps      | 640          |\n",
                        "| train/                  |              |\n",
                        "|    approx_kl            | 0.0016249828 |\n",
                        "|    clip_fraction        | 0.025        |\n",
                        "|    clip_range           | 0.2          |\n",
                        "|    entropy_loss         | -0.164       |\n",
                        "|    explained_variance   | 0            |\n",
                        "|    learning_rate        | 0.01         |\n",
                        "|    loss                 | 25.6         |\n",
                        "|    n_updates            | 190          |\n",
                        "|    policy_gradient_loss | 0.00122      |\n",
                        "|    value_loss           | 51.7         |\n",
                        "------------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 11.8        |\n",
                        "|    ep_rew_mean          | -78.4       |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 5           |\n",
                        "|    iterations           | 21          |\n",
                        "|    time_elapsed         | 132         |\n",
                        "|    total_timesteps      | 672         |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.006652128 |\n",
                        "|    clip_fraction        | 0.0219      |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.128      |\n",
                        "|    explained_variance   | -1.19e-07   |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 13.2        |\n",
                        "|    n_updates            | 200         |\n",
                        "|    policy_gradient_loss | -0.00335    |\n",
                        "|    value_loss           | 30.9        |\n",
                        "-----------------------------------------\n",
                        "-------------------------------------------\n",
                        "| rollout/                |               |\n",
                        "|    ep_len_mean          | 11.6          |\n",
                        "|    ep_rew_mean          | -77.1         |\n",
                        "| time/                   |               |\n",
                        "|    fps                  | 5             |\n",
                        "|    iterations           | 22            |\n",
                        "|    time_elapsed         | 138           |\n",
                        "|    total_timesteps      | 704           |\n",
                        "| train/                  |               |\n",
                        "|    approx_kl            | 1.4066696e-05 |\n",
                        "|    clip_fraction        | 0             |\n",
                        "|    clip_range           | 0.2           |\n",
                        "|    entropy_loss         | -0.0783       |\n",
                        "|    explained_variance   | 0             |\n",
                        "|    learning_rate        | 0.01          |\n",
                        "|    loss                 | 7.8           |\n",
                        "|    n_updates            | 210           |\n",
                        "|    policy_gradient_loss | -6.33e-09     |\n",
                        "|    value_loss           | 16.7          |\n",
                        "-------------------------------------------\n",
                        "-----------------------------------------\n",
                        "| rollout/                |             |\n",
                        "|    ep_len_mean          | 11.4        |\n",
                        "|    ep_rew_mean          | -76.3       |\n",
                        "| time/                   |             |\n",
                        "|    fps                  | 5           |\n",
                        "|    iterations           | 23          |\n",
                        "|    time_elapsed         | 144         |\n",
                        "|    total_timesteps      | 736         |\n",
                        "| train/                  |             |\n",
                        "|    approx_kl            | 0.029997222 |\n",
                        "|    clip_fraction        | 0.0281      |\n",
                        "|    clip_range           | 0.2         |\n",
                        "|    entropy_loss         | -0.035      |\n",
                        "|    explained_variance   | -1.19e-07   |\n",
                        "|    learning_rate        | 0.01        |\n",
                        "|    loss                 | 9.62        |\n",
                        "|    n_updates            | 220         |\n",
                        "|    policy_gradient_loss | -0.00461    |\n",
                        "|    value_loss           | 19.6        |\n",
                        "-----------------------------------------\n",
                        "-------------------------------------------\n",
                        "| rollout/                |               |\n",
                        "|    ep_len_mean          | 11.2          |\n",
                        "|    ep_rew_mean          | -74.3         |\n",
                        "| time/                   |               |\n",
                        "|    fps                  | 5             |\n",
                        "|    iterations           | 24            |\n",
                        "|    time_elapsed         | 149           |\n",
                        "|    total_timesteps      | 768           |\n",
                        "| train/                  |               |\n",
                        "|    approx_kl            | 3.5762787e-07 |\n",
                        "|    clip_fraction        | 0             |\n",
                        "|    clip_range           | 0.2           |\n",
                        "|    entropy_loss         | -0.0128       |\n",
                        "|    explained_variance   | 0             |\n",
                        "|    learning_rate        | 0.01          |\n",
                        "|    loss                 | 16.7          |\n",
                        "|    n_updates            | 230           |\n",
                        "|    policy_gradient_loss | -1.29e-08     |\n",
                        "|    value_loss           | 33.6          |\n",
                        "-------------------------------------------\n",
                        "--------------------------------------\n",
                        "| rollout/                |          |\n",
                        "|    ep_len_mean          | 11       |\n",
                        "|    ep_rew_mean          | -72      |\n",
                        "| time/                   |          |\n",
                        "|    fps                  | 5        |\n",
                        "|    iterations           | 25       |\n",
                        "|    time_elapsed         | 155      |\n",
                        "|    total_timesteps      | 800      |\n",
                        "| train/                  |          |\n",
                        "|    approx_kl            | 0.0      |\n",
                        "|    clip_fraction        | 0        |\n",
                        "|    clip_range           | 0.2      |\n",
                        "|    entropy_loss         | -0.00917 |\n",
                        "|    explained_variance   | 0        |\n",
                        "|    learning_rate        | 0.01     |\n",
                        "|    loss                 | 26.5     |\n",
                        "|    n_updates            | 240      |\n",
                        "|    policy_gradient_loss | 6.15e-09 |\n",
                        "|    value_loss           | 53.1     |\n",
                        "--------------------------------------\n",
                        "--------------------------------------\n",
                        "| rollout/                |          |\n",
                        "|    ep_len_mean          | 10.9     |\n",
                        "|    ep_rew_mean          | -71.3    |\n",
                        "| time/                   |          |\n",
                        "|    fps                  | 5        |\n",
                        "|    iterations           | 26       |\n",
                        "|    time_elapsed         | 161      |\n",
                        "|    total_timesteps      | 832      |\n",
                        "| train/                  |          |\n",
                        "|    approx_kl            | 0.0      |\n",
                        "|    clip_fraction        | 0        |\n",
                        "|    clip_range           | 0.2      |\n",
                        "|    entropy_loss         | -0.00816 |\n",
                        "|    explained_variance   | 0        |\n",
                        "|    learning_rate        | 0.01     |\n",
                        "|    loss                 | 40.2     |\n",
                        "|    n_updates            | 250      |\n",
                        "|    policy_gradient_loss | 8.66e-09 |\n",
                        "|    value_loss           | 87.3     |\n",
                        "--------------------------------------\n",
                        "--------------------------------------\n",
                        "| rollout/                |          |\n",
                        "|    ep_len_mean          | 10.8     |\n",
                        "|    ep_rew_mean          | -69.7    |\n",
                        "| time/                   |          |\n",
                        "|    fps                  | 5        |\n",
                        "|    iterations           | 27       |\n",
                        "|    time_elapsed         | 167      |\n",
                        "|    total_timesteps      | 864      |\n",
                        "| train/                  |          |\n",
                        "|    approx_kl            | 0.0      |\n",
                        "|    clip_fraction        | 0        |\n",
                        "|    clip_range           | 0.2      |\n",
                        "|    entropy_loss         | -0.00783 |\n",
                        "|    explained_variance   | 0        |\n",
                        "|    learning_rate        | 0.01     |\n",
                        "|    loss                 | 18.3     |\n",
                        "|    n_updates            | 260      |\n",
                        "|    policy_gradient_loss | 4.84e-09 |\n",
                        "|    value_loss           | 38.1     |\n",
                        "--------------------------------------\n",
                        "--------------------------------------\n",
                        "| rollout/                |          |\n",
                        "|    ep_len_mean          | 10.6     |\n",
                        "|    ep_rew_mean          | -68.7    |\n",
                        "| time/                   |          |\n",
                        "|    fps                  | 5        |\n",
                        "|    iterations           | 28       |\n",
                        "|    time_elapsed         | 174      |\n",
                        "|    total_timesteps      | 896      |\n",
                        "| train/                  |          |\n",
                        "|    approx_kl            | 0.0      |\n",
                        "|    clip_fraction        | 0        |\n",
                        "|    clip_range           | 0.2      |\n",
                        "|    entropy_loss         | -0.00772 |\n",
                        "|    explained_variance   | 5.96e-08 |\n",
                        "|    learning_rate        | 0.01     |\n",
                        "|    loss                 | 27.8     |\n",
                        "|    n_updates            | 270      |\n",
                        "|    policy_gradient_loss | 1.63e-09 |\n",
                        "|    value_loss           | 55.7     |\n",
                        "--------------------------------------\n",
                        "---------------------------------------\n",
                        "| rollout/                |           |\n",
                        "|    ep_len_mean          | 10.5      |\n",
                        "|    ep_rew_mean          | -68.2     |\n",
                        "| time/                   |           |\n",
                        "|    fps                  | 5         |\n",
                        "|    iterations           | 29        |\n",
                        "|    time_elapsed         | 180       |\n",
                        "|    total_timesteps      | 928       |\n",
                        "| train/                  |           |\n",
                        "|    approx_kl            | 0.0       |\n",
                        "|    clip_fraction        | 0         |\n",
                        "|    clip_range           | 0.2       |\n",
                        "|    entropy_loss         | -0.00768  |\n",
                        "|    explained_variance   | 0         |\n",
                        "|    learning_rate        | 0.01      |\n",
                        "|    loss                 | 48.7      |\n",
                        "|    n_updates            | 280       |\n",
                        "|    policy_gradient_loss | -1.02e-09 |\n",
                        "|    value_loss           | 116       |\n",
                        "---------------------------------------\n",
                        "--------------------------------------\n",
                        "| rollout/                |          |\n",
                        "|    ep_len_mean          | 10.4     |\n",
                        "|    ep_rew_mean          | -67.8    |\n",
                        "| time/                   |          |\n",
                        "|    fps                  | 5        |\n",
                        "|    iterations           | 30       |\n",
                        "|    time_elapsed         | 187      |\n",
                        "|    total_timesteps      | 960      |\n",
                        "| train/                  |          |\n",
                        "|    approx_kl            | 0.0      |\n",
                        "|    clip_fraction        | 0        |\n",
                        "|    clip_range           | 0.2      |\n",
                        "|    entropy_loss         | -0.00767 |\n",
                        "|    explained_variance   | 0        |\n",
                        "|    learning_rate        | 0.01     |\n",
                        "|    loss                 | 40.1     |\n",
                        "|    n_updates            | 290      |\n",
                        "|    policy_gradient_loss | 4.84e-09 |\n",
                        "|    value_loss           | 79.9     |\n",
                        "--------------------------------------\n",
                        "---------------------------------------\n",
                        "| rollout/                |           |\n",
                        "|    ep_len_mean          | 9.98      |\n",
                        "|    ep_rew_mean          | -65.5     |\n",
                        "| time/                   |           |\n",
                        "|    fps                  | 5         |\n",
                        "|    iterations           | 31        |\n",
                        "|    time_elapsed         | 192       |\n",
                        "|    total_timesteps      | 992       |\n",
                        "| train/                  |           |\n",
                        "|    approx_kl            | 0.0       |\n",
                        "|    clip_fraction        | 0         |\n",
                        "|    clip_range           | 0.2       |\n",
                        "|    entropy_loss         | -0.00766  |\n",
                        "|    explained_variance   | -1.19e-07 |\n",
                        "|    learning_rate        | 0.01      |\n",
                        "|    loss                 | 8.76      |\n",
                        "|    n_updates            | 300       |\n",
                        "|    policy_gradient_loss | -2.72e-08 |\n",
                        "|    value_loss           | 23.4      |\n",
                        "---------------------------------------\n",
                        "---------------------------------------\n",
                        "| rollout/                |           |\n",
                        "|    ep_len_mean          | 9.28      |\n",
                        "|    ep_rew_mean          | -58.7     |\n",
                        "| time/                   |           |\n",
                        "|    fps                  | 5         |\n",
                        "|    iterations           | 32        |\n",
                        "|    time_elapsed         | 198       |\n",
                        "|    total_timesteps      | 1024      |\n",
                        "| train/                  |           |\n",
                        "|    approx_kl            | 0.0       |\n",
                        "|    clip_fraction        | 0         |\n",
                        "|    clip_range           | 0.2       |\n",
                        "|    entropy_loss         | -0.00766  |\n",
                        "|    explained_variance   | -1.19e-07 |\n",
                        "|    learning_rate        | 0.01      |\n",
                        "|    loss                 | 42.6      |\n",
                        "|    n_updates            | 310       |\n",
                        "|    policy_gradient_loss | -1.96e-09 |\n",
                        "|    value_loss           | 85.8      |\n",
                        "---------------------------------------\n",
                        "--------------------------------------\n",
                        "| rollout/                |          |\n",
                        "|    ep_len_mean          | 8.99     |\n",
                        "|    ep_rew_mean          | -57.4    |\n",
                        "| time/                   |          |\n",
                        "|    fps                  | 5        |\n",
                        "|    iterations           | 33       |\n",
                        "|    time_elapsed         | 203      |\n",
                        "|    total_timesteps      | 1056     |\n",
                        "| train/                  |          |\n",
                        "|    approx_kl            | 0.0      |\n",
                        "|    clip_fraction        | 0        |\n",
                        "|    clip_range           | 0.2      |\n",
                        "|    entropy_loss         | -0.00766 |\n",
                        "|    explained_variance   | 0        |\n",
                        "|    learning_rate        | 0.01     |\n",
                        "|    loss                 | 21.5     |\n",
                        "|    n_updates            | 320      |\n",
                        "|    policy_gradient_loss | 3.35e-09 |\n",
                        "|    value_loss           | 43       |\n",
                        "--------------------------------------\n",
                        "---------------------------------------\n",
                        "| rollout/                |           |\n",
                        "|    ep_len_mean          | 8.75      |\n",
                        "|    ep_rew_mean          | -56       |\n",
                        "| time/                   |           |\n",
                        "|    fps                  | 5         |\n",
                        "|    iterations           | 34        |\n",
                        "|    time_elapsed         | 209       |\n",
                        "|    total_timesteps      | 1088      |\n",
                        "| train/                  |           |\n",
                        "|    approx_kl            | 0.0       |\n",
                        "|    clip_fraction        | 0         |\n",
                        "|    clip_range           | 0.2       |\n",
                        "|    entropy_loss         | -0.00766  |\n",
                        "|    explained_variance   | 0         |\n",
                        "|    learning_rate        | 0.01      |\n",
                        "|    loss                 | 12.7      |\n",
                        "|    n_updates            | 330       |\n",
                        "|    policy_gradient_loss | -1.86e-08 |\n",
                        "|    value_loss           | 32.8      |\n",
                        "---------------------------------------\n",
                        "---------------------------------------\n",
                        "| rollout/                |           |\n",
                        "|    ep_len_mean          | 8.65      |\n",
                        "|    ep_rew_mean          | -55.2     |\n",
                        "| time/                   |           |\n",
                        "|    fps                  | 5         |\n",
                        "|    iterations           | 35        |\n",
                        "|    time_elapsed         | 215       |\n",
                        "|    total_timesteps      | 1120      |\n",
                        "| train/                  |           |\n",
                        "|    approx_kl            | 0.0       |\n",
                        "|    clip_fraction        | 0         |\n",
                        "|    clip_range           | 0.2       |\n",
                        "|    entropy_loss         | -0.00766  |\n",
                        "|    explained_variance   | -1.19e-07 |\n",
                        "|    learning_rate        | 0.01      |\n",
                        "|    loss                 | 55.5      |\n",
                        "|    n_updates            | 340       |\n",
                        "|    policy_gradient_loss | -1.43e-08 |\n",
                        "|    value_loss           | 113       |\n",
                        "---------------------------------------\n",
                        "--------------------------------------\n",
                        "| rollout/                |          |\n",
                        "|    ep_len_mean          | 8.59     |\n",
                        "|    ep_rew_mean          | -54.2    |\n",
                        "| time/                   |          |\n",
                        "|    fps                  | 5        |\n",
                        "|    iterations           | 36       |\n",
                        "|    time_elapsed         | 221      |\n",
                        "|    total_timesteps      | 1152     |\n",
                        "| train/                  |          |\n",
                        "|    approx_kl            | 0.0      |\n",
                        "|    clip_fraction        | 0        |\n",
                        "|    clip_range           | 0.2      |\n",
                        "|    entropy_loss         | -0.00766 |\n",
                        "|    explained_variance   | 0        |\n",
                        "|    learning_rate        | 0.01     |\n",
                        "|    loss                 | 31.3     |\n",
                        "|    n_updates            | 350      |\n",
                        "|    policy_gradient_loss | 2.35e-08 |\n",
                        "|    value_loss           | 80.5     |\n",
                        "--------------------------------------\n"
                    ]
                }
            ],
            "source": [
                "model.learn(total_timesteps=100000, callback=callback)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# model = PPO.load('./train/best_model_20000')\n",
                "test_env = TetrisSingleEnv(obs_type=\"grid\")\n",
                "state = test_env.reset()\n",
                "i = 0\n",
                "\n",
                "while True:\n",
                "    if (i >= 1000):\n",
                "        env.close()\n",
                "        break\n",
                "    action, _ = model.predict(state)\n",
                "    state, reward, done, info = test_env.step(action)\n",
                "    print(\"reward\", reward)\n",
                "    print(done)\n",
                "    test_env.render()\n",
                "    i += 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "state = naked_env.reset()\n",
                "print(state)\n",
                "print(model.predict(state))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
